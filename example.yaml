# Training configuration with multiple stages
script_path: train.py

training:
  stage-01:
    datasets:
      - /workspace/data/dfrc99-16tb7p-eval-filt-v2.min.binpack

    # Training parameters
    lambda: 1.0
    num-workers: 32

    # Epoch settings
    max_epochs: 5

    network-save-period: 100
    save-last-network: true

    # Hardware settings
    accelerator: gpu
    devices: 1
    # precision: 16

    default_root_dir: logs/stage1

  stage-02:
    datasets:
      - /workspace/data/dfrc99-16tb7p-eval-filt-v2.min.binpack

    lr: 4.375e-4
    num-workers: 6

    max_epochs: 5
    end-lambda: 0.75
    gamma: 0.995
    early-fen-skipping: 12

    network-save-period: 100
    save-last-network: true

    accelerator: gpu
    devices: 1
    # precision: 16

    # Different output directory
    default_root_dir: logs/stage2
